cat > README.md << 'EOF'
# ðŸ¤– Sistema RAG GestorÃ­a Alex

Sistema inteligente de gestiÃ³n documental con IA para gestorÃ­as y asesorÃ­as fiscales.

![Python](https://img.shields.io/badge/python-3.9+-blue.svg)
![Streamlit](https://img.shields.io/badge/streamlit-1.28+-red.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

## âœ¨ CaracterÃ­sticas

- **Chat Inteligente con IA**: ConversaciÃ³n natural con razonamiento avanzado
- **RAG (Retrieval Augmented Generation)**: BÃºsqueda semÃ¡ntica en documentos
- **GeneraciÃ³n AutomÃ¡tica**: Crea documentos TXT y Excel profesionales
- **Multi-modelo IA**: Llama 3.2 (rÃ¡pido) y Qwen 2.5 (preciso)
- **Procesamiento Robusto**: PDF y Excel con mÃºltiples mÃ©todos de extracciÃ³n
- **Portal de Clientes**: Interfaz independiente para acceso de clientes
- **Biblioteca Inteligente**: GestiÃ³n completa de documentos procesados

## ðŸ“‹ Requisitos Previos

- Python 3.9 o superior
- [Ollama](https://ollama.ai/) instalado
- 8GB RAM mÃ­nimo (16GB recomendado)
- macOS, Linux o Windows (WSL)

## ðŸš€ InstalaciÃ³n

### 1. Clonar el repositorio
```bash
git clone https://github.com/TU_USUARIO/rag-gestoria.git
cd rag-gestoria
```

### 2. Crear entorno virtual
```bash
python3 -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

### 3. Instalar dependencias
```bash
pip install -r requirements.txt --break-system-packages
```

### 4. Instalar modelos de IA
```bash
# AsegÃºrate de tener Ollama instalado
ollama pull llama3.2
ollama pull qwen2.5:14b
ollama pull nomic-embed-text
```

### 5. Dar permisos a scripts (macOS/Linux)
```bash
chmod +x *.sh
```

## ðŸ’» Uso

### Iniciar el Sistema
```bash
# Activar entorno virtual
source venv/bin/activate

# Iniciar panel de administraciÃ³n
streamlit run app_admin.py --server.address 0.0.0.0 --server.port 8501
```

### Acceso

- **Panel Admin**: http://localhost:8501
- **Portal Clientes**: http://localhost:8502 (si ejecutas `dashboard_cliente.py`)

## ðŸ“š Capacidades del Chat

### Consultar Documentos
```
"Â¿QuÃ© documentos tiene Juan?"
"Busca informaciÃ³n sobre IVA en todos los archivos"
"Analiza el contrato de MarÃ­a"
```

### Generar Documentos TXT
```
"Genera un informe fiscal de Juan"
"Crea una carta formal para el cliente"
"Redacta un resumen ejecutivo"
```

### Generar Excel
```
"Genera un Excel con todos los clientes y sus documentos"
"Crea una tabla comparativa de facturas"
"Exporta los datos a formato Excel"
```

### Conocimiento General
```
"Â¿CÃ³mo se calcula el IRPF?"
"Â¿CuÃ¡ndo se presenta el modelo 347?"
"ExplÃ­came las deducciones fiscales para autÃ³nomos"
```

## ðŸ“ Estructura del Proyecto
```
rag-gestoria/
â”œâ”€â”€ app_admin.py              # Interfaz principal de administraciÃ³n
â”œâ”€â”€ procesador_hibrido.py     # Motor RAG y procesamiento
â”œâ”€â”€ dashboard_cliente.py      # Portal para clientes
â”œâ”€â”€ documentos/
â”‚   â”œâ”€â”€ entrada/              # Documentos a procesar
â”‚   â”œâ”€â”€ procesados/           # Documentos procesados
â”‚   â”œâ”€â”€ resumenes/            # ResÃºmenes generados
â”‚   â””â”€â”€ generados/            # TXT y Excel generados
â”œâ”€â”€ chroma_db/                # Base de datos vectorial
â”œâ”€â”€ documentacion/            # DocumentaciÃ³n del proyecto
â”œâ”€â”€ requirements.txt          # Dependencias Python
â””â”€â”€ README.md                 # Este archivo
```

## ðŸ› ï¸ TecnologÃ­as

- **Frontend**: [Streamlit](https://streamlit.io/)
- **IA/LLM**: [Ollama](https://ollama.ai/) (Llama 3.2, Qwen 2.5)
- **Embeddings**: nomic-embed-text
- **Vector DB**: [ChromaDB](https://www.trychroma.com/)
- **PDF Processing**: PyPDF2, pdfplumber, PyMuPDF
- **Data**: Pandas, OpenPyXL
- **VisualizaciÃ³n**: Plotly

## ðŸ”§ ConfiguraciÃ³n

### Cambiar Puerto

Edita los scripts o usa:
```bash
streamlit run app_admin.py --server.port 8080
```

### Modelos de IA

Por defecto usa:
- **Llama 3.2**: Consultas rÃ¡pidas
- **Qwen 2.5 14B**: AnÃ¡lisis complejos

Para cambiar modelos, edita las constantes en `procesador_hibrido.py`:
```python
MODELO_RAPIDO = "llama3.2"
MODELO_CALIDAD = "qwen2.5:14b"
```

## ðŸ“Š CaracterÃ­sticas TÃ©cnicas

- **Chunking**: 700 palabras, 150 overlap
- **BÃºsqueda**: Top-k semÃ¡ntica con ChromaDB
- **GeneraciÃ³n**: Razonamiento en 3 pasos
- **Formatos soportados**: PDF, XLSX, XLS
- **Salida**: TXT, XLSX con formato profesional

## ðŸ› SoluciÃ³n de Problemas

### Error: Puerto ocupado
```bash
pkill -f streamlit
```

### Error: Modelos no encontrados
```bash
ollama list
ollama pull llama3.2
ollama pull qwen2.5:14b
```

### Error: Permisos en macOS
```bash
chmod +x *.sh
```

## ðŸ“ Roadmap

- [ ] AutenticaciÃ³n de usuarios
- [ ] Roles y permisos
- [ ] IntegraciÃ³n con APIs externas (AEAT)
- [ ] OCR avanzado
- [ ] ExportaciÃ³n a Word/PDF
- [ ] Notificaciones automÃ¡ticas
- [ ] Firma digital de documentos

## ðŸ¤ Contribuir

Las contribuciones son bienvenidas! Por favor:

1. Fork el proyecto
2. Crea tu rama (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ðŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver `LICENSE` para mÃ¡s detalles.

## ðŸ‘¤ Autor

**Alex** - @alete.c

## ðŸ™ Agradecimientos

- [Ollama](https://ollama.ai/) por los modelos de IA locales
- [Streamlit](https://streamlit.io/) por el framework
- [ChromaDB](https://www.trychroma.com/) por la base de datos vectorial

---

â­ Si este proyecto te fue Ãºtil, Â¡dale una estrella en GitHub!
EOF
